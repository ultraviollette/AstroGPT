import streamlit as st
import os
import io
from typing import Any, Type, List
import httpx 
from langchain.chat_models import ChatOpenAI
from langchain.tools import BaseTool, DuckDuckGoSearchResults, WikipediaQueryRun
from langchain.utilities import WikipediaAPIWrapper
from langchain.agents import initialize_agent, AgentType
from langchain.schema import SystemMessage
from langchain.document_loaders import WebBaseLoader
from pydantic import BaseModel, Field

# 1. ì „ì—­ ìƒíƒœ ë° ìœ í‹¸ë¦¬í‹° (st.session_stateë¡œ ëŒ€ì²´)

# Agentê°€ ìƒì„±í•œ ìµœì¢… í…ìŠ¤íŠ¸ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•œ ë”•ì…”ë„ˆë¦¬ë¥¼ st.session_stateë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.

@st.cache_resource
def get_llm(openai_api_key):
    """LLM ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìºì‹œí•˜ì—¬ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤."""
    if not openai_api_key:
        return None
    return ChatOpenAI(
        temperature=0.1,
        model="gpt-4o-mini",
        openai_api_key=openai_api_key
    )

# 2. ì»¤ìŠ¤í…€ ë„êµ¬ ì •ì˜

class DuckDuckGoSearchToolArgsSchema(BaseModel):
    query: str = Field(description="The query you will search for")

class DuckDuckGoSearchTool(BaseTool):
    name = "DuckDuckGoSearchTool"
    description = """
    Use this tool to perform web searches using the DuckDuckGo search engine.
    It takes a query as an argument.
    Example query: "Latest technology news"
    """
    args_schema: Type[DuckDuckGoSearchToolArgsSchema] = DuckDuckGoSearchToolArgsSchema
    return_direct: bool = False

    def _run(self, query) -> Any:
        # LangChainì˜ ë‚´ì¥ DuckDuckGoSearchResults ì‚¬ìš©
        search = DuckDuckGoSearchResults(max_results=3) # ê²°ê³¼ë¥¼ 3ê°œë¡œ ì œí•œ
        try:
            # HTTPError ì²˜ë¦¬ ë¡œì§ ì¶”ê°€
            return search.run(query)
        except Exception as e:
            # httpx.HTTPErrorë¥¼ í¬í•¨í•œ ëª¨ë“  ì ì¬ì ì¸ ë„¤íŠ¸ì›Œí¬/HTTP ì˜¤ë¥˜ë¥¼ í¬ì°©í•©ë‹ˆë‹¤.
            if isinstance(e, httpx.HTTPError) or "HTTPError" in str(e):
                return "DuckDuckGo search failed due to a network or server error. Please rely on other tools for this step."
            # ë‹¤ë¥¸ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ëŠ” ë‹¤ì‹œ ë°œìƒì‹œí‚µë‹ˆë‹¤.
            raise e


class WikipediaSearchToolArgsSchema(BaseModel):
    query: str = Field(description="The query you will search for on Wikipedia")

class WikipediaSearchTool(BaseTool):
    name = "WikipediaSearchTool"
    description = """
    Use this tool to perform searches on Wikipedia.
    It takes a query as an argument.
    Example query: "Artificial Intelligence"
    """
    args_schema: Type[WikipediaSearchToolArgsSchema] = WikipediaSearchToolArgsSchema
    return_direct: bool = False

    def _run(self, query) -> Any:
        wiki = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())
        return wiki.run(query)

class WebScrapingToolArgsSchema(BaseModel):
    url: str = Field(description="The URL of the website you want to scrape")

class WebScrapingTool(BaseTool):
    name = "WebScrapingTool"
    description = """
    If you found a potentially useful website link through DuckDuckGo,
    Use this to get the textual content of that link for detailed research.
    """
    args_schema: Type[WebScrapingToolArgsSchema] = WebScrapingToolArgsSchema
    return_direct: bool = False

    def _run(self, url):
        try:
            loader = WebBaseLoader([url])
            docs = loader.load()
            text = "\n\n".join([doc.page_content for doc in docs])
            
            # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ Agent ì¶”ë¡ ì„ ìœ„í•´ ì¼ë¶€ë§Œ ë°˜í™˜
            MAX_CHARACTERS = 4000
            if len(text) > MAX_CHARACTERS:
                return f"Successfully scraped URL: {url}. Extracted content (first {MAX_CHARACTERS} chars): {text[:MAX_CHARACTERS]}..."
                
            return f"Successfully scraped URL: {url}. Extracted content:\n{text}"
        except Exception as e:
            return f"Error scraping URL {url}: {e}"

class SaveToTXTToolArgsSchema(BaseModel):
    text: str = Field(description="The detailed, final research result text you will save to a file.")

class SaveToTXTTool(BaseTool):
    name = "SaveToTXTTool"
    description = """
    Use this tool to save the *FINAL, COMPLETE* research content as a .txt file.
    This should be the very last step before concluding the research.
    """
    args_schema: Type[SaveToTXTToolArgsSchema] = SaveToTXTToolArgsSchema
    return_direct: bool = True # ì´ ë„êµ¬ê°€ í˜¸ì¶œë˜ë©´ AgentëŠ” ìµœì¢… ë‹µë³€ì„ ë°˜í™˜í•´ì•¼ í•¨

    def _run(self, text) -> Any:
        st.session_state.saved_research["content"] = text
        return "Research results successfully prepared and marked for saving. Agent should now proceed with the Final Answer."


# 3. Agent ì´ˆê¸°í™” ë° ì‹¤í–‰ ë¡œì§

@st.cache_resource(experimental_allow_widgets=True)
def initialize_research_agent(_llm_instance):
    """ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ë„êµ¬ë¥¼ ì„¤ì •í•˜ì—¬ Agentë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    if not _llm_instance:
        return None
        
    system_message_content = """
    You are a research expert.
    Your task is to use Wikipedia or DuckDuckGo to gather comprehensive and accurate information about the query provided.
    When you find a relevant website link through DuckDuckGo, you must use the 'WebScrapingTool' to get the content from that website. 
    Combine information from Wikipedia, DuckDuckGo searches, and any relevant websites you find. Ensure that the final answer is well-organized, detailed, and includes citations with links (URLs) for all sources used.
    Your research should be saved to a .txt file using the 'SaveToTXTTool', and the content should match the detailed findings you provide to the user.
    The information from Wikipedia must be included if relevant.
    You must always call the 'SaveToTXTTool' as the last step before returning the final response.
    """
    
    agent = initialize_agent(
        llm=_llm_instance,
        verbose=True,
        agent=AgentType.OPENAI_FUNCTIONS,
        tools=[
            DuckDuckGoSearchTool(),
            WikipediaSearchTool(),
            WebScrapingTool(),
            SaveToTXTTool(),
        ],
        agent_kwargs={"system_message": SystemMessage(content=system_message_content)},
        handle_parsing_errors=True
    )
    return agent

def run_agent_and_update_chat(agent, query):
    """
    Agentë¥¼ ì‹¤í–‰í•˜ê³  Streamlit ì„¸ì…˜ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    """
    
    # Agent ì‹¤í–‰ ì „, ì´ì „ ì—°êµ¬ ê²°ê³¼ë¥¼ ì§€ìš°ê³  ìƒˆ ì¿¼ë¦¬ë¥¼ st.session_stateì— ê¸°ë¡í•©ë‹ˆë‹¤.**
    st.session_state.saved_research["content"] = None
    st.session_state.saved_research["query"] = query
    
    try:
        # Agent ì‹¤í–‰
        result = agent.run(query)
        
        # Agent ê²°ê³¼ ì €ì¥
        st.session_state.chat_history.append({"role": "assistant", "message": result})
        
    except Exception as e:
        # --- ì˜¤ë¥˜ ì²˜ë¦¬ ë¡œì§ ìœ ì§€ ë° ê°œì„  ---
        error_message = f"Agent Run failed: {type(e).__name__}: {e}. Please check your API Key (Quota) or query complexity/network issues."
        
        # 1. ì˜¤ë¥˜ ë©”ì‹œì§€ ì¶œë ¥
        st.error(error_message)
        
        # 2. ìì„¸í•œ íŠ¸ë ˆì´ìŠ¤ë°±ì„ UIì— í‘œì‹œ (ë””ë²„ê¹… ëª©ì )
        st.exception(e)
        
        # 3. ì±„íŒ… ê¸°ë¡ì— ì˜¤ë¥˜ ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.chat_history.append({"role": "assistant", "message": f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {type(e).__name__}: {e}"})


# 4. Streamlit UI

# 4.1. ì´ˆê¸° ì„¤ì • ë° ì‚¬ì´ë“œë°”
st.set_page_config(
    page_title="AssistantGPT - LangChain Research Agent",
    page_icon="ğŸ”",
)

st.title("AssistantGPT")

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
    
# íŒŒì¼ ì €ì¥ ìƒíƒœë¥¼ ìœ„í•œ st.session_state ì´ˆê¸°í™”
if "saved_research" not in st.session_state:
    st.session_state.saved_research = {"content": None, "query": None}


openai_api_key = None

with st.sidebar:
    st.markdown("## Configuration")
    
    openai_api_key = st.text_input(
        "OpenAI API Key",
        type="password",
        placeholder="Enter your OpenAI API Key...",
    )
    
    st.markdown("---")
    st.markdown(
        """
        ### About this App
        This application uses a **LangChain Agent (OpenAI Functions)** to perform research.
        It utilizes the following custom tools:
        1.  ğŸŒ **DuckDuckGoSearchTool** (Web search)
        2.  ğŸ§  **WikipediaSearchTool** (Detailed background)
        3.  ğŸ“„ **WebScrapingTool** (Extract content from URLs)
        4.  ğŸ’¾ **SaveToTXTTool** (Saves final research)
        The Agent combines information from these sources to provide comprehensive research results.
        """
    )

    st.markdown("---")
    st.markdown("[GitHub Repository Link](https://github.com/ultraviollette/AstroGPT)") 
    st.markdown("---")

    if st.button("Clear Chat History"):
        st.session_state.chat_history = []
        st.session_state.saved_research = {"content": None, "query": None} # ì €ì¥ ìƒíƒœ ì´ˆê¸°í™”
        st.cache_resource.clear() 
        st.rerun()


# 4.2. ë©”ì¸ ë¡œì§

# Agent ì´ˆê¸°í™”
llm = get_llm(openai_api_key)
if not llm:
    st.info("âš ï¸ Please enter your OpenAI API Key in the sidebar to proceed.")
    st.stop()
    
agent = initialize_research_agent(llm)

# 1. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("Ask the agent to research a topic (e.g., 'Research about the XZ backdoor and its impact')..."):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ê¸°ë¡
    st.session_state.chat_history.append({"role": "user", "message": prompt})
    
    with st.spinner(f"Running Research Agent for: {prompt}"):
        run_agent_and_update_chat(agent, prompt)

# 2. ëŒ€í™” ê¸°ë¡ í‘œì‹œ
for message in st.session_state.chat_history:
    with st.chat_message(message["role"]):
        st.markdown(message["message"])

# 3. ì €ì¥ëœ ì½˜í…ì¸  í‘œì‹œ ë° ë‹¤ìš´ë¡œë“œ
# st.session_stateì—ì„œ ë°ì´í„°ë¥¼ ì½ì–´ì™€ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì„ ë Œë”ë§í•©ë‹ˆë‹¤.
if st.session_state.saved_research["content"]:
    content = st.session_state.saved_research["content"]
    query = st.session_state.saved_research["query"]
    
    st.success("âœ… Research complete! The final results have been saved by the Agent.")
    
    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    download_filename = f"{query.replace(' ', '_')}_research.txt"
    st.download_button(
        label=f"â¬‡ï¸ Download {download_filename}",
        data=content,
        file_name=download_filename,
        mime="text/plain",
        key='download_research_txt'
    )
    
    # ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
    with st.expander("ğŸ“ View Saved Research Content"):
        st.code(content, language='markdown')
    
